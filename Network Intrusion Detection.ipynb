{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f2ef7-9a65-4ac7-bd4c-36f911bf2f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8ef436-6c11-4cbd-bcce-035814fdc4be",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b597c2-c277-4f5e-a24c-9cf22cd933c3",
   "metadata": {},
   "source": [
    "### The dataset does not have headers, so we'll add them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463679ca-f9da-4389-8d71-7c65f645ea73",
   "metadata": {},
   "source": [
    "### The column names are available from the NSL-KDD documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ea5f5-db10-4bbc-a700-2b09fd6686e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'class', 'difficulty'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0322226-86b2-4408-bd00-4d7613f86e61",
   "metadata": {},
   "source": [
    "### Load the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548068b9-6380-4551-bcfd-07f37738dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('KDDTrain+.txt', header=None, names=columns)\n",
    "df_test = pd.read_csv('KDDTest+.txt', header=None, names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb1010d-9f0d-4d5e-bb96-4f575ded503c",
   "metadata": {},
   "source": [
    "### Drop the 'difficulty' column as it's not needed for detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b3231e-4354-4433-a335-54e49fe681df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['difficulty'], axis=1, inplace=True)\n",
    "df_test.drop(['difficulty'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108bf8ca-d9a1-4e69-9e41-1afea39cc7f2",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4a7155-88f5-4822-928a-8def153d504b",
   "metadata": {},
   "source": [
    "### Identify categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6147ff7-8200-4e5d-b357-f1cd982a2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "numerical_cols = df_train.select_dtypes(include=np.number).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43f650-7b59-41f3-8e8e-6f98161db184",
   "metadata": {},
   "source": [
    "### The 'class' column is our target label\n",
    "### Remove it from the numerical columns list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9629b-85da-466c-86ee-baf096504595",
   "metadata": {},
   "source": [
    "### These are actually binary, but we'll scale them anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff60ad-1c7c-477e-abc6-ed2aff12b9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols.remove('land') \n",
    "numerical_cols.remove('logged_in')\n",
    "numerical_cols.remove('is_host_login')\n",
    "numerical_cols.remove('is_guest_login')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a9039c-e210-41ef-8a63-e263b12e440d",
   "metadata": {},
   "source": [
    "### --- Feature Encoding for Categorical Features ---\n",
    "### We use one-hot encoding to convert categorical features into a numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3f25d-8819-4f17-83f9-d0a8461e0e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train, df_test])\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ea3c56-4b44-48ae-9127-8b7bfe3bb182",
   "metadata": {},
   "source": [
    "### Separate the combined data back into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f0853-b267-4a4b-b5f8-6615b8ff144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows = len(df_train)\n",
    "train_df = df.iloc[:train_rows]\n",
    "test_df = df.iloc[train_rows:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7328b7-e3e1-4d65-a822-4aa74d752cee",
   "metadata": {},
   "source": [
    "### --- Label Encoding for the 'class' column ---\n",
    "### We change the 'class' label to be binary: 0 for 'normal' and 1 for 'attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a26a52-27ef-4638-851b-4f4e90278f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df['class'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "test_labels = test_df['class'].apply(lambda x: 0 if x == 'normal' else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3523d98-619a-4a3e-90aa-da304f2432b7",
   "metadata": {},
   "source": [
    "### Drop the original class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef85ce1-2e49-4acb-9d81-d730d77091c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['class'], axis=1, inplace=True)\n",
    "test_df.drop(['class'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad9cc5d-4421-4461-909d-f35f6fcde6c5",
   "metadata": {},
   "source": [
    "### --- Normalization for Numerical Features ---\n",
    "### Scale numerical features to a range of [0, 1] for better model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f138c1-2191-4131-8156-f19179108b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a488314c-edcc-44eb-8403-ffcbd0f83187",
   "metadata": {},
   "source": [
    "### Convert to numpy arrays from model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f10af-d916-4ad2-bb6a-5e28591840bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays for model training\n",
    "X_train = train_df.values\n",
    "y_train = train_labels.values\n",
    "X_test = test_df.values\n",
    "y_test = test_labels.values\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8f9f08-b112-42fc-ad40-14c8ab8fb22a",
   "metadata": {},
   "source": [
    "### Step 3: Training Traditional ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb849fc-f65f-4d43-8fec-3a737ca2c327",
   "metadata": {},
   "source": [
    "### Now, we'll train the traditional models you listed: \n",
    "### KNN, LDA, and SVM. We will use \n",
    "### scikit-learn for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36291e21-a832-42bf-b909-17da1af39cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea636381-6c75-4efa-a282-f43e305922ad",
   "metadata": {},
   "source": [
    "### --- Initialize Models ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc943938-8bc7-4057-8ca3-ddcfaa01d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"K-Nearest Neighbours (KNN)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Linear Discriminant Analysis (LDA)\": LinearDiscriminantAnalysis(),\n",
    "    \"Support Vector Machine (SVM)\": SVC(kernel='linear', probability=True) # Using a linear kernel for speed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cdaa59-809d-4c84-b90d-128daa2e502b",
   "metadata": {},
   "source": [
    "### --- Train and Evaluate Models ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f961ce0-3026-4d24-8149-8096288f423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"--- Training {name} ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"--- Evaluating {name} ---\")\n",
    "    y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86eddd7-6e88-46ba-94a0-b581fbc8286c",
   "metadata": {},
   "source": [
    "### --- Performance Metrics ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b63fe-6c86-416d-add3-ccfb8686c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"----------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa31dd1-ef95-4de6-8080-1578ba341bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559fc31-c84e-4a73-a46c-ca91ecae6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "results_list.append(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84188b0-0300-4c16-bd0a-aed6c04e3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Final Model Performance Summary ---\")\n",
    "\n",
    "# Print the table header\n",
    "print(f\"{'Model':<35} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1-Score':<10}\")\n",
    "print(\"-\" * 85)\n",
    "\n",
    "# Print the results for each model\n",
    "for result in results_list:\n",
    "    print(f\"{result['Model']:<35} | {result['Accuracy']:.4f}     | {result['Precision']:.4f}    | {result['Recall']:.4f}   | {result['F1-Score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0a20a27c-59c3-4d8b-aba2-e41d3837cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Data Loading and Preprocessing ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_7212\\3410752078.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop(['class'], axis=1, inplace=True)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_7212\\3410752078.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop(['class'], axis=1, inplace=True)\n",
      "C:\\Users\\varsh\\AppData\\Local\\Temp\\ipykernel_7212\\3410752078.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (125973, 122)\n",
      "Test data shape: (22544, 122)\n",
      "--- Preprocessing Complete ---\n",
      "\n",
      "--- Training K-Nearest Neighbors (KNN) ---\n",
      "--- Evaluating K-Nearest Neighbors (KNN) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.93      0.78      9711\n",
      "           1       0.92      0.65      0.76     12833\n",
      "\n",
      "    accuracy                           0.77     22544\n",
      "   macro avg       0.80      0.79      0.77     22544\n",
      "weighted avg       0.81      0.77      0.77     22544\n",
      "\n",
      "'K-Nearest Neighbors (KNN)' results have been stored.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Linear Discriminant Analysis (LDA) ---\n",
      "--- Evaluating Linear Discriminant Analysis (LDA) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.93      0.77      9711\n",
      "           1       0.92      0.63      0.75     12833\n",
      "\n",
      "    accuracy                           0.76     22544\n",
      "   macro avg       0.79      0.78      0.76     22544\n",
      "weighted avg       0.81      0.76      0.76     22544\n",
      "\n",
      "'Linear Discriminant Analysis (LDA)' results have been stored.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Training Support Vector Machine (SVM) ---\n",
      "--- Evaluating Support Vector Machine (SVM) ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.92      0.76      9711\n",
      "           1       0.92      0.62      0.74     12833\n",
      "\n",
      "    accuracy                           0.75     22544\n",
      "   macro avg       0.78      0.77      0.75     22544\n",
      "weighted avg       0.80      0.75      0.75     22544\n",
      "\n",
      "'Support Vector Machine (SVM)' results have been stored.\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Final Model Performance Summary ---\n",
      "                             Model  Accuracy  Precision   Recall  F1-Score\n",
      "         K-Nearest Neighbors (KNN)  0.769384   0.924017 0.648173  0.761896\n",
      "Linear Discriminant Analysis (LDA)  0.761666   0.924926 0.632666  0.751377\n",
      "      Support Vector Machine (SVM)  0.753948   0.916343 0.624795  0.742992\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings from LDA about collinear features\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "\n",
    "# --- Step 2: Data Loading and Preprocessing ---\n",
    "\n",
    "print(\"--- Starting Data Loading and Preprocessing ---\")\n",
    "\n",
    "# Define the column names for the NSL-KDD dataset\n",
    "columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins',\n",
    "    'logged_in', 'num_compromised', 'root_shell', 'su_attempted', 'num_root',\n",
    "    'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds',\n",
    "    'is_host_login', 'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
    "    'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
    "    'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate', 'class', 'difficulty'\n",
    "]\n",
    "\n",
    "# Load the training and test datasets\n",
    "df_train = pd.read_csv('KDDTrain+.txt', header=None, names=columns)\n",
    "df_test = pd.read_csv('KDDTest+.txt', header=None, names=columns)\n",
    "\n",
    "# Drop the 'difficulty' column\n",
    "df_train.drop(['difficulty'], axis=1, inplace=True)\n",
    "df_test.drop(['difficulty'], axis=1, inplace=True)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "numerical_cols = df_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "# Combine train and test sets for consistent one-hot encoding\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "# Perform one-hot encoding\n",
    "for col in categorical_cols:\n",
    "    dummies = pd.get_dummies(df[col], prefix=col)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# Separate back into training and testing sets\n",
    "train_rows = len(df_train)\n",
    "train_df = df.iloc[:train_rows]\n",
    "test_df = df.iloc[train_rows:]\n",
    "\n",
    "# Create binary labels: 0 for 'normal' and 1 for 'attack'\n",
    "train_labels = train_df['class'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "test_labels = test_df['class'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# Drop the original 'class' column\n",
    "train_df.drop(['class'], axis=1, inplace=True)\n",
    "test_df.drop(['class'], axis=1, inplace=True)\n",
    "\n",
    "# Align columns - crucial for models to work correctly\n",
    "# Some 'service' types might be in train but not test, or vice-versa\n",
    "train_cols = train_df.columns\n",
    "test_cols = test_df.columns\n",
    "missing_in_test = set(train_cols) - set(test_cols)\n",
    "for c in missing_in_test:\n",
    "    test_df[c] = 0\n",
    "missing_in_train = set(test_cols) - set(train_cols)\n",
    "for c in missing_in_train:\n",
    "    train_df[c] = 0\n",
    "test_df = test_df[train_cols] # Ensure order is the same\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = MinMaxScaler()\n",
    "train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "# Convert dataframes to numpy arrays\n",
    "X_train = train_df.values\n",
    "y_train = train_labels.values\n",
    "X_test = test_df.values\n",
    "y_test = test_labels.values\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(\"--- Preprocessing Complete ---\\n\")\n",
    "\n",
    "# --- Step 3: Train, Evaluate, and Store Results ---\n",
    "\n",
    "# Initialize the models\n",
    "# Added solver='svd' to LDA to make it more robust against collinear features from one-hot encoding\n",
    "models = {\n",
    "    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Linear Discriminant Analysis (LDA)\": LinearDiscriminantAnalysis(solver='svd'),\n",
    "    \"Support Vector Machine (SVM)\": SVC(kernel='linear')\n",
    "}\n",
    "\n",
    "# Create a list to store the results dictionaries\n",
    "results_list = []\n",
    "\n",
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    print(f\"--- Training {name} ---\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"--- Evaluating {name} ---\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Print the individual report for this model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Store results in a dictionary and append to the list\n",
    "    model_results = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "    results_list.append(model_results)\n",
    "    print(f\"'{name}' results have been stored.\")\n",
    "    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "# --- Step 4: Display Final Summary Table ---\n",
    "\n",
    "print(\"--- Final Model Performance Summary ---\")\n",
    "\n",
    "# Create a DataFrame from the results list for pretty printing\n",
    "results_df = pd.DataFrame(results_list)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c81c6-0655-4557-b076-5ccde99a8aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
